"""
DDL ë°ì´í„°ë¥¼ DBML í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì»¨ë²„í„°
"""

from typing import Dict, List, Optional, Tuple
import re
import os
from pathlib import Path


class DBMLConverter:
    """DDL íŒŒì‹± ê²°ê³¼ë¥¼ DBML í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        # MySQL íƒ€ì…ì„ DBML íƒ€ì…ìœ¼ë¡œ ë§¤í•‘
        self.type_mapping = {
            'BIGINT': 'bigint',
            'INT': 'int',
            'INTEGER': 'int',
            'SMALLINT': 'smallint',
            'TINYINT': 'tinyint',
            'DECIMAL': 'decimal',
            'NUMERIC': 'decimal',
            'FLOAT': 'float',
            'DOUBLE': 'double',
            'VARCHAR': 'varchar',
            'CHAR': 'char',
            'TEXT': 'text',
            'LONGTEXT': 'longtext',
            'MEDIUMTEXT': 'mediumtext',
            'TINYTEXT': 'tinytext',
            'DATE': 'date',
            'DATETIME': 'datetime',
            'TIMESTAMP': 'timestamp',
            'TIME': 'time',
            'YEAR': 'year',
            'BLOB': 'blob',
            'LONGBLOB': 'longblob',
            'MEDIUMBLOB': 'mediumblob',
            'TINYBLOB': 'tinyblob',
            'BINARY': 'binary',
            'VARBINARY': 'varbinary',
            'ENUM': 'enum',
            'SET': 'set',
            'JSON': 'json',
            'BOOLEAN': 'boolean',
            'BOOL': 'boolean'
        }
    
    def convert_tables_to_dbml(self, tables_data: Dict[str, Dict], schema_name: str = None) -> str:
        """í…Œì´ë¸” ë°ì´í„°ë¥¼ DBML í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        dbml_content = []
        
        # í”„ë¡œì íŠ¸ ì •ë³´ (ì„ íƒì )
        if schema_name:
            dbml_content.append(f"Project {schema_name} {{")
            dbml_content.append("  database_type: 'MySQL'")
            dbml_content.append("}\n")
        
        # ê° í…Œì´ë¸”ì„ DBMLë¡œ ë³€í™˜
        for table_name, table_info in tables_data.items():
            table_dbml = self._convert_table_to_dbml(table_name, table_info)
            dbml_content.append(table_dbml)
            dbml_content.append("")  # í…Œì´ë¸” ê°„ ë¹ˆ ì¤„
        
        # ê´€ê³„(References) ì¶”ê°€
        references = self._extract_references(tables_data)
        if references:
            dbml_content.append("// Relationships")
            for ref in references:
                dbml_content.append(ref)
        
        return "\n".join(dbml_content)
    
    def _convert_table_to_dbml(self, table_name: str, table_info: Dict) -> str:
        """ë‹¨ì¼ í…Œì´ë¸”ì„ DBML í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        safe_table_name = self._escape_table_name(table_name)
        lines = [f"Table {safe_table_name} {{"]
        
        # Primary Key ì •ë³´ë¥¼ ì œì•½ì¡°ê±´ì—ì„œ ê°€ì ¸ì™€ì„œ ì»¬ëŸ¼ì— ì ìš©
        primary_key_columns = set()
        constraints = table_info.get('constraints', [])
        for constraint in constraints:
            if constraint['type'] == 'primary_key':
                primary_key_columns.update([col.lower() for col in constraint['columns']])
        
        # ì»¬ëŸ¼ ì •ì˜
        for column in table_info.get('columns', []):
            # Primary key ì •ë³´ ì¶”ê°€
            if column['name'].lower() in primary_key_columns:
                column['primary_key'] = True
            
            column_line = self._convert_column_to_dbml(column)
            lines.append(f"  {column_line}")
        
        # ì¸ë±ìŠ¤ ì •ì˜ (ê·¸ë£¹í™”)
        constraints = table_info.get('constraints', [])
        index_definitions = []
        
        for constraint in constraints:
            if constraint['type'] == 'primary_key':
                # Primary keyëŠ” ì»¬ëŸ¼ ë ˆë²¨ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìŠ¤í‚µ
                continue
            elif constraint['type'] == 'unique':
                # ì‹¤ì œ ì»¬ëŸ¼ëª… ì°¾ê¸°
                actual_cols = self._get_actual_column_names(table_info, constraint['columns'])
                columns_str = ', '.join(actual_cols)
                index_definitions.append(f"    ({columns_str}) [unique]")
            elif constraint['type'] == 'index':
                # ì‹¤ì œ ì»¬ëŸ¼ëª… ì°¾ê¸°
                actual_cols = self._get_actual_column_names(table_info, constraint['columns'])
                columns_str = ', '.join(actual_cols)
                index_definitions.append(f"    ({columns_str})")
        
        # ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ í•˜ë‚˜ì˜ Indexes ë¸”ë¡ìœ¼ë¡œ ê·¸ë£¹í™”
        if index_definitions:
            lines.append("")
            lines.append("  Indexes {")
            lines.extend(index_definitions)
            lines.append("  }")
        
        lines.append("}")
        
        return "\n".join(lines)
    
    def _convert_column_to_dbml(self, column: Dict) -> str:
        """ì»¬ëŸ¼ ì •ì˜ë¥¼ DBML í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        name = self._escape_table_name(column['name'])
        
        # íƒ€ì… ë³€í™˜
        mysql_type = column['type'].upper()
        dbml_type = self.type_mapping.get(mysql_type, mysql_type.lower())
        
        # í¬ê¸° ì •ë³´ ì¶”ê°€
        if column.get('size'):
            size_info = column['size']
            # ENUM íƒ€ì…ì˜ ê²½ìš° ê°’ë“¤ì„ ì´ìŠ¤ì¼€ì´í”„
            if mysql_type == 'ENUM' and size_info:
                # ENUM('value1','value2') í˜•íƒœì—ì„œ ê° ê°’ì„ ì´ìŠ¤ì¼€ì´í”„
                size_info = self._escape_enum_values(size_info)
            
            if ',' in size_info:  # DECIMAL(10,2) ê°™ì€ ê²½ìš°
                dbml_type += f"({size_info})"
            else:  # VARCHAR(255) ê°™ì€ ê²½ìš°
                dbml_type += f"({size_info})"
        
        # ì†ì„± ìˆ˜ì§‘
        attributes = []
        
        if column.get('primary_key'):
            attributes.append('pk')
        
        if column.get('auto_increment'):
            attributes.append('increment')
        
        if not column.get('nullable', True):
            attributes.append('not null')
        
        if column.get('unique') and not column.get('primary_key'):
            attributes.append('unique')
        
        if column.get('default') is not None:
            default_value = column['default']
            # DBMLì—ì„œ ì§€ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if default_value.upper() == 'CURRENT_TIMESTAMP':
                default_value = '`now()`'  # í•¨ìˆ˜ í‘œí˜„ì‹ì€ ë°±í‹±ìœ¼ë¡œ ê°ì‹¸ê¸°
            elif default_value.upper() == 'NULL':
                default_value = 'null'
            elif self._is_date_format(default_value):
                # ë‚ ì§œ í˜•ì‹ì€ ë¬¸ìì—´ë¡œ ì²˜ë¦¬ (0000-00-00, 0000-00-00 00:00:00 ë“±)
                default_value = f"'{default_value}'"
            elif self._is_ip_address(default_value):
                # IP ì£¼ì†ŒëŠ” ë¬¸ìì—´ë¡œ ì²˜ë¦¬ (0.0.0.0, 192.168.1.1 ë“±)
                default_value = f"'{default_value}'"
            elif default_value.isdigit() or (default_value.replace('.', '').isdigit() and '.' in default_value and not self._is_date_format(default_value) and not self._is_ip_address(default_value)):
                # ìˆœìˆ˜ ì •ìˆ˜ ë˜ëŠ” ì†Œìˆ˜ì  ìˆ«ìë§Œ ê·¸ëŒ€ë¡œ (í•˜ì´í”ˆì´ í¬í•¨ëœ ê°’ì€ ë¬¸ìì—´ë¡œ ì²˜ë¦¬)
                pass
            elif default_value.lower() in ['true', 'false']:
                # booleanì€ ê·¸ëŒ€ë¡œ
                pass
            else:
                # ë‚˜ë¨¸ì§€ëŠ” ë¬¸ìì—´ ë¦¬í„°ëŸ´ë¡œ ì²˜ë¦¬ (íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„)
                default_value = f"'{self._escape_string_value(default_value)}'"
            attributes.append(f'default: {default_value}')
        
        # ìµœì¢… ì»¬ëŸ¼ ì •ì˜ êµ¬ì„±
        column_def = f"{name} {dbml_type}"
        
        if attributes:
            attributes_str = ', '.join(attributes)
            column_def += f" [{attributes_str}]"
        
        return column_def
    
    def _escape_string_value(self, value: str) -> str:
        """
        DBML ë¬¸ìì—´ ê°’ì—ì„œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„
        
        Args:
            value: ì´ìŠ¤ì¼€ì´í”„í•  ë¬¸ìì—´
            
        Returns:
            ì´ìŠ¤ì¼€ì´í”„ëœ ë¬¸ìì—´
        """
        if not isinstance(value, str):
            return str(value)
        
        # DBMLì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” ë¬¸ìë“¤ì„ ì´ìŠ¤ì¼€ì´í”„
        escaped = value.replace('\\', '\\\\')  # ë°±ìŠ¬ë˜ì‹œ
        escaped = escaped.replace('\n', '\\n')  # ì¤„ë°”ê¿ˆ
        escaped = escaped.replace('\r', '\\r')  # ìºë¦¬ì§€ ë¦¬í„´
        escaped = escaped.replace('\t', '\\t')  # íƒ­
        escaped = escaped.replace("'", "\\'")   # ì‘ì€ë”°ì˜´í‘œ
        escaped = escaped.replace('"', '\\"')   # í°ë”°ì˜´í‘œ
        
        # ì œì–´ë¬¸ì ì œê±° (ì¶œë ¥ ê°€ëŠ¥í•œ ASCII ë¬¸ìë§Œ ìœ ì§€)
        escaped = ''.join(char if ord(char) >= 32 and ord(char) <= 126 else f'\\x{ord(char):02x}' for char in escaped)
        
        return escaped
    
    def _is_date_format(self, value: str) -> bool:
        """
        ê°’ì´ ë‚ ì§œ/ì‹œê°„ í˜•ì‹ì¸ì§€ í™•ì¸
        
        Args:
            value: í™•ì¸í•  ê°’
            
        Returns:
            ë‚ ì§œ/ì‹œê°„ í˜•ì‹ì´ë©´ True
        """
        import re
        
        # ì¼ë°˜ì ì¸ MySQL ë‚ ì§œ/ì‹œê°„ í˜•ì‹ë“¤
        date_patterns = [
            r'^\d{4}-\d{2}-\d{2}$',  # 0000-00-00
            r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$',  # 0000-00-00 00:00:00
            r'^\d{2}:\d{2}:\d{2}$',  # 00:00:00
        ]
        
        for pattern in date_patterns:
            if re.match(pattern, value):
                return True
        
        return False
    
    def _is_ip_address(self, value: str) -> bool:
        """
        ê°’ì´ IP ì£¼ì†Œ í˜•ì‹ì¸ì§€ í™•ì¸
        
        Args:
            value: í™•ì¸í•  ê°’
            
        Returns:
            IP ì£¼ì†Œ í˜•ì‹ì´ë©´ True
        """
        import re
        
        # IPv4 ì£¼ì†Œ í˜•ì‹ (0.0.0.0 ~ 255.255.255.255)
        ipv4_pattern = r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$'
        
        # ë¶ˆì™„ì „í•œ IP ì£¼ì†Œ í˜•íƒœë„ í¬í•¨ (0.0.0, 192.168.1 ë“±)
        partial_ip_pattern = r'^\d{1,3}(\.\d{1,3}){1,3}$'
        
        if re.match(ipv4_pattern, value):
            # ì™„ì „í•œ IP ì£¼ì†Œì¸ ê²½ìš° ê° ì˜¥í…Ÿì´ 0-255 ë²”ìœ„ì¸ì§€ í™•ì¸
            parts = value.split('.')
            return all(0 <= int(part) <= 255 for part in parts)
        elif re.match(partial_ip_pattern, value):
            # ë¶ˆì™„ì „í•œ IP ì£¼ì†Œ í˜•íƒœë„ IP ì£¼ì†Œë¡œ ì²˜ë¦¬
            parts = value.split('.')
            return all(0 <= int(part) <= 255 for part in parts)
        
        return False
    
    def _escape_enum_values(self, enum_str: str) -> str:
        """
        ENUM ê°’ë“¤ì—ì„œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„
        
        Args:
            enum_str: ENUM ê°’ ë¬¸ìì—´ (ì˜ˆ: "'value1','value2'")
            
        Returns:
            ì´ìŠ¤ì¼€ì´í”„ëœ ENUM ê°’ ë¬¸ìì—´
        """
        # ENUM ê°’ë“¤ì„ íŒŒì‹±í•˜ê³  ê°ê° ì´ìŠ¤ì¼€ì´í”„
        import re
        
        # 'value1','value2' í˜•íƒœì—ì„œ ê° ê°’ì„ ì¶”ì¶œ
        values = re.findall(r"'([^']*)'", enum_str)
        if not values:
            # ë‹¤ë¥¸ í˜•íƒœì¼ ìˆ˜ë„ ìˆìŒ
            return enum_str
        
        # ê° ê°’ì„ ì´ìŠ¤ì¼€ì´í”„í•˜ê³  ë‹¤ì‹œ ì¡°í•©
        escaped_values = []
        for value in values:
            escaped_value = self._escape_string_value(value)
            escaped_values.append(f"'{escaped_value}'")
        
        return ','.join(escaped_values)
    
    def _escape_table_name(self, name: str) -> str:
        """
        í…Œì´ë¸”/ì»¬ëŸ¼ ì´ë¦„ì—ì„œ DBMLì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” ë¬¸ì ì²˜ë¦¬
        
        Args:
            name: í…Œì´ë¸”/ì»¬ëŸ¼ ì´ë¦„
            
        Returns:
            ì•ˆì „í•œ ì´ë¦„
        """
        # ê³µë°±ì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ëœ ê²½ìš° ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸°
        if ' ' in name or any(char in name for char in ['-', '.', '/', '\\', '(', ')', '[', ']']):
            return f'"{name}"'
        return name
    
    def _extract_references(self, tables_data: Dict[str, Dict]) -> List[str]:
        """Foreign Key ê´€ê³„ë¥¼ DBML Reference í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œ"""
        references = []
        # ì¤‘ë³µ ê´€ê³„ ë°©ì§€ë¥¼ ìœ„í•œ set
        seen_references = set()
        
        for table_name, table_info in tables_data.items():
            constraints = table_info.get('constraints', [])
            
            for constraint in constraints:
                if constraint['type'] == 'foreign_key':
                    # ì‹¤ì œ ì»¬ëŸ¼ëª… ì°¾ê¸° (ëŒ€ì†Œë¬¸ì êµ¬ë¶„)
                    source_cols = self._get_actual_column_names(table_info, constraint['columns'])
                    target_table_info, actual_target_table_name = self._find_table_in_data_with_name(tables_data, constraint['ref_table'])
                    target_cols = self._get_actual_column_names(target_table_info, constraint['ref_columns']) if target_table_info else constraint['ref_columns']
                    
                    # ì‹¤ì œ í…Œì´ë¸”ëª… ì‚¬ìš©
                    target_table_name = actual_target_table_name if actual_target_table_name else constraint['ref_table']
                    
                    # ë‹¨ì¼ ì»¬ëŸ¼ FKì¸ ê²½ìš°
                    if len(source_cols) == 1 and len(target_cols) == 1:
                        ref_line = (f"Ref: {table_name}.{source_cols[0]} "
                                  f"> {target_table_name}.{target_cols[0]}")
                        # ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€
                        if ref_line not in seen_references:
                            references.append(ref_line)
                            seen_references.add(ref_line)
                    elif len(source_cols) == len(target_cols) and len(source_cols) > 0:
                        # ë³µí•© ì»¬ëŸ¼ FKì¸ ê²½ìš° - ë‹¨ì¼ ì»¬ëŸ¼ ê´€ê³„ë“¤ë¡œ ë¶„ë¦¬
                        # dbdiagram.ioì—ì„œ ë³µí•© í‚¤ ê´€ê³„ê°€ ì œëŒ€ë¡œ ì¸ì‹ë˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìˆìŒ
                        for i in range(len(source_cols)):
                            ref_line = f"Ref: {table_name}.{source_cols[i]} > {target_table_name}.{target_cols[i]}"
                            # ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€
                            if ref_line not in seen_references:
                                references.append(ref_line)
                                seen_references.add(ref_line)
        
        return references
    
    def _get_actual_column_names(self, table_info: Dict, column_names: List[str]) -> List[str]:
        """í…Œì´ë¸” ì •ì˜ì—ì„œ ì‹¤ì œ ì»¬ëŸ¼ëª… ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ì •í™•íˆ ë§ì¶¤)"""
        if not table_info or 'columns' not in table_info:
            return column_names
        
        actual_columns = []
        table_columns = {col['name'].lower(): col['name'] for col in table_info['columns']}
        
        for col_name in column_names:
            # ì†Œë¬¸ìë¡œ ë¹„êµí•´ì„œ ì‹¤ì œ ì»¬ëŸ¼ëª… ì°¾ê¸°
            actual_name = table_columns.get(col_name.lower(), col_name)
            actual_columns.append(actual_name)
        
        return actual_columns
    
    def _find_table_in_data(self, tables_data: Dict[str, Dict], table_name: str) -> Optional[Dict]:
        """í…Œì´ë¸” ë°ì´í„°ì—ì„œ íŠ¹ì • í…Œì´ë¸” ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)"""
        for tname, tinfo in tables_data.items():
            if tname.lower() == table_name.lower():
                return tinfo
        return None
    
    def _find_table_in_data_with_name(self, tables_data: Dict[str, Dict], table_name: str) -> Tuple[Optional[Dict], Optional[str]]:
        """í…Œì´ë¸” ë°ì´í„°ì—ì„œ íŠ¹ì • í…Œì´ë¸” ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ) - ì‹¤ì œ í…Œì´ë¸”ëª…ë„ ë°˜í™˜"""
        for tname, tinfo in tables_data.items():
            if tname.lower() == table_name.lower():
                return tinfo, tname
        return None, None
    
    def save_dbml_file(self, dbml_content: str, output_path: str):
        """DBML ë‚´ìš©ì„ íŒŒì¼ë¡œ ì €ì¥"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(dbml_content)
    
    def validate_and_fix_missing_columns(self, dbml_content: str, schema_dir: str) -> str:
        """DBML íŒŒì¼ì—ì„œ ëˆ„ë½ëœ ì»¬ëŸ¼ë“¤ì„ ì°¾ì•„ì„œ ìˆ˜ì •"""
        
        if not os.path.exists(schema_dir):
            return dbml_content
        
        # ê° í…Œì´ë¸”ë³„ë¡œ í™•ì¸
        table_pattern = r'Table\s+(\w+)\s*\{([^}]+)\}'
        tables = re.findall(table_pattern, dbml_content, re.MULTILINE | re.DOTALL)
        
        fixed_content = dbml_content
        changes_made = False
        
        for table_name, table_content in tables:
            # í•´ë‹¹ DDL íŒŒì¼ ì°¾ê¸°
            ddl_file = os.path.join(schema_dir, f"{table_name}.sql")
            if not os.path.exists(ddl_file):
                continue
            
            # DDLì—ì„œ ì‹¤ì œ ì»¬ëŸ¼ ëª©ë¡ ì¶”ì¶œ
            ddl_columns = self._extract_columns_from_ddl_file(ddl_file)
            ddl_column_names = {col['name'] for col in ddl_columns}
            
            # DBMLì—ì„œ í˜„ì¬ ì»¬ëŸ¼ ëª©ë¡ ì¶”ì¶œ (ë” ì •í™•í•œ íŒ¨í„´ ì‚¬ìš©)
            # ì»¬ëŸ¼ ì •ì˜ ë¼ì¸ë“¤ë§Œ ì¶”ì¶œ (ì¸ë±ìŠ¤, ì œì•½ì¡°ê±´ ë“± ì œì™¸)
            lines = table_content.split('\n')
            dbml_column_names = set()
            for line in lines:
                line = line.strip()
                # ì»¬ëŸ¼ ì •ì˜ ë¼ì¸ì¸ì§€ í™•ì¸ (ê³µë°±ìœ¼ë¡œ ì‹œì‘í•˜ê³  ì‹ë³„ìë¡œ ì‹œì‘)
                if line and not line.startswith('Indexes') and not line.startswith('FK_') and not line.startswith('//'):
                    # ì •ê·œì‹ìœ¼ë¡œ ì»¬ëŸ¼ëª… ì¶”ì¶œ
                    col_match = re.match(r'^\s*(\w+)\s+', line)
                    if col_match:
                        dbml_column_names.add(col_match.group(1))
            
            # ëˆ„ë½ëœ ì»¬ëŸ¼ë“¤ ì°¾ê¸°
            missing_columns = ddl_column_names - dbml_column_names
            
            if missing_columns:
                print(f"  ğŸ”§ í…Œì´ë¸” {table_name}ì—ì„œ ëˆ„ë½ëœ ì»¬ëŸ¼ ìˆ˜ì •: {', '.join(missing_columns)}")
                
                # ëˆ„ë½ëœ ì»¬ëŸ¼ë“¤ì˜ ì •ì˜ ìƒì„±
                missing_col_definitions = []
                for col in ddl_columns:
                    if col['name'] in missing_columns:
                        # DBML í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        dbml_type = self._convert_sql_type_to_dbml(col['type'])
                        attributes = []
                        
                        if not col['nullable']:
                            attributes.append('not null')
                        if col['auto_increment']:
                            attributes.append('increment')
                        if col['default']:
                            if col['default'].upper() == 'CURRENT_TIMESTAMP':
                                attributes.append('default: `now()`')
                            elif col['default'].upper() == 'NULL':
                                attributes.append('default: null')
                            elif col['default'].isdigit() or col['default'].replace('.', '').replace('-', '').isdigit():
                                attributes.append(f"default: {col['default']}")
                            elif col['default'].lower() in ['true', 'false']:
                                attributes.append(f"default: {col['default'].lower()}")
                            else:
                                # ë¬¸ìì—´ ê¸°ë³¸ê°’
                                escaped_default = self._escape_string_value(col['default'])
                                attributes.append(f"default: '{escaped_default}'")
                        
                        attr_str = f" [{', '.join(attributes)}]" if attributes else ""
                        # ì»¬ëŸ¼ëª…ì—ì„œ ê³µë°± ì œê±°
                        clean_column_name = col['name'].replace(' ', '_')
                        missing_col_definitions.append(f"  {clean_column_name} {dbml_type}{attr_str}")
                
                # DBML í…Œì´ë¸” ì •ì˜ì— ëˆ„ë½ëœ ì»¬ëŸ¼ë“¤ ì¶”ê°€
                if missing_col_definitions:
                    # ê¸°ì¡´ í…Œì´ë¸” ì •ì˜ ì°¾ê¸°
                    old_table_def = f"Table {table_name} {{{table_content}}}"
                    
                    # ì¶”ê°€í•˜ê¸° ì „ì— í˜„ì¬ í…Œì´ë¸” ë‚´ìš©ì—ì„œ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë“¤ ë‹¤ì‹œ í™•ì¸
                    existing_in_table = set()
                    for line in table_content.split('\n'):
                        line = line.strip()
                        if line and not line.startswith('Indexes') and not line.startswith('FK_') and not line.startswith('//'):
                            col_match = re.match(r'^\s*(\w+)\s+', line)
                            if col_match:
                                existing_in_table.add(col_match.group(1))
                    
                    # ì¤‘ë³µ ë°©ì§€: ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ ì •ì˜ëŠ” ì œì™¸
                    filtered_definitions = []
                    for col_def in missing_col_definitions:
                        col_name_match = re.match(r'\s*(\w+)\s+', col_def)
                        if col_name_match:
                            col_name = col_name_match.group(1)
                            if col_name not in existing_in_table:
                                filtered_definitions.append(col_def)
                                existing_in_table.add(col_name)  # ì¶”ê°€ëœ ì»¬ëŸ¼ë„ ê¸°ë¡
                    
                    if filtered_definitions:
                        # Indexes ì„¹ì…˜ì´ ìˆìœ¼ë©´ ê·¸ ì•ì—, ì—†ìœ¼ë©´ í…Œì´ë¸” ëì— ì¶”ê°€
                        if "Indexes {" in table_content:
                            # Indexes ì•ì— ì¶”ê°€
                            indexes_pos = table_content.find("\n  Indexes {")
                            before_indexes = table_content[:indexes_pos]
                            after_indexes = table_content[indexes_pos:]
                            new_content = before_indexes + "\n" + "\n".join(filtered_definitions) + "\n" + after_indexes
                        else:
                            # í…Œì´ë¸” ëì— ì¶”ê°€
                            new_content = table_content.rstrip() + "\n" + "\n".join(filtered_definitions) + "\n"
                        
                        # ì¸ë±ìŠ¤ì—ì„œ ì˜ëª»ëœ ì»¬ëŸ¼ëª… ì°¸ì¡° ìˆ˜ì •
                        new_content = self._fix_index_column_references(new_content, ddl_columns)
                        
                        new_table_def = f"Table {table_name} {{{new_content}}}"
                        fixed_content = fixed_content.replace(old_table_def, new_table_def)
                        changes_made = True
        
        if changes_made:
            print(f"  âœ… ëˆ„ë½ëœ ì»¬ëŸ¼ë“¤ì„ ìë™ìœ¼ë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.")
        
        return fixed_content
    
    def _fix_index_column_references(self, table_content: str, ddl_columns: List[Dict]) -> str:
        """ì¸ë±ìŠ¤ì—ì„œ ì˜ëª»ëœ ì»¬ëŸ¼ëª… ì°¸ì¡°ë¥¼ ìˆ˜ì •"""
        # DDLì—ì„œ ì‹¤ì œ ì»¬ëŸ¼ëª… ë§¤í•‘ ìƒì„± (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
        column_mapping = {}
        for col in ddl_columns:
            column_mapping[col['name'].lower()] = col['name']
        
        lines = table_content.split('\n')
        fixed_lines = []
        
        in_indexes = False
        for line in lines:
            if 'Indexes {' in line:
                in_indexes = True
                fixed_lines.append(line)
            elif in_indexes and line.strip() == '}':
                in_indexes = False
                fixed_lines.append(line)
            elif in_indexes:
                # ì¸ë±ìŠ¤ ë¼ì¸ì—ì„œ ì»¬ëŸ¼ëª… ìˆ˜ì •
                fixed_line = line
                for col in ddl_columns:
                    actual_name = col['name']
                    # ë‹¤ì–‘í•œ ì¼€ì´ìŠ¤ ë§¤ì¹­
                    patterns = [
                        actual_name.upper(),  # BEGINPIT
                        actual_name.lower(),  # beginpit
                        actual_name,          # BeginPIT
                    ]
                    
                    for pattern_name in patterns:
                        if pattern_name != actual_name:
                            # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ ë‹¨ì–´ ê²½ê³„ ì‚¬ìš©
                            pattern = r'\b' + re.escape(pattern_name) + r'\b'
                            fixed_line = re.sub(pattern, actual_name, fixed_line)
                
                fixed_lines.append(fixed_line)
            else:
                fixed_lines.append(line)
        
        return '\n'.join(fixed_lines)
    
    def _extract_columns_from_ddl_file(self, ddl_file_path: str) -> List[Dict]:
        """DDL íŒŒì¼ì—ì„œ ì»¬ëŸ¼ë“¤ì„ ì§ì ‘ ì¶”ì¶œ (íŒŒì„œê°€ ë†“ì¹˜ëŠ” ì»¬ëŸ¼ë“¤ë„ í¬í•¨)"""
        with open(ddl_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ê°„ë‹¨í•œ ì •ê·œì‹ìœ¼ë¡œ ì»¬ëŸ¼ ì •ì˜ ì°¾ê¸°
        column_pattern = r'`([^`]+)`\s+([a-zA-Z]+(?:\([^)]*\))?)\s+([^,]+?)(?=,|\n\s*(?:PRIMARY|UNIQUE|KEY|CONSTRAINT|\)))'
        matches = re.findall(column_pattern, content, re.MULTILINE | re.DOTALL)
        
        columns = []
        for match in matches:
            col_name = match[0]
            col_type = match[1] 
            attributes = match[2].strip()
            
            # ê¸°ë³¸ ì†ì„± íŒŒì‹±
            nullable = 'NOT NULL' not in attributes.upper()
            auto_increment = 'AUTO_INCREMENT' in attributes.upper()
            
            # DEFAULT ê°’ ì¶”ì¶œ
            default_match = re.search(r"DEFAULT\s+([^'\s]+|'[^']*')", attributes, re.IGNORECASE)
            default_value = default_match.group(1) if default_match else None
            if default_value and default_value.startswith("'") and default_value.endswith("'"):
                default_value = default_value[1:-1]  # ë”°ì˜´í‘œ ì œê±°
            
            columns.append({
                'name': col_name,
                'type': col_type.upper(),
                'nullable': nullable,
                'auto_increment': auto_increment,
                'default': default_value
            })
        
        return columns
    
    def _convert_sql_type_to_dbml(self, sql_type: str) -> str:
        """SQL íƒ€ì…ì„ DBML íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        sql_type = sql_type.upper()
        
        # ê¸°ë³¸ íƒ€ì… ë§¤í•‘
        type_mapping = {
            'TINYINT': 'tinyint',
            'SMALLINT': 'smallint', 
            'MEDIUMINT': 'int',
            'INT': 'int',
            'INTEGER': 'int',
            'BIGINT': 'bigint',
            'DECIMAL': 'decimal',
            'NUMERIC': 'decimal',
            'FLOAT': 'float',
            'DOUBLE': 'double',
            'BIT': 'bit',
            'CHAR': 'char',
            'VARCHAR': 'varchar',
            'BINARY': 'binary',
            'VARBINARY': 'varbinary',
            'TINYBLOB': 'blob',
            'BLOB': 'blob',
            'MEDIUMBLOB': 'blob',
            'LONGBLOB': 'blob',
            'TINYTEXT': 'text',
            'TEXT': 'text',
            'MEDIUMTEXT': 'text',
            'LONGTEXT': 'longtext',
            'ENUM': 'enum',
            'SET': 'set',
            'DATE': 'date',
            'TIME': 'time',
            'DATETIME': 'datetime',
            'TIMESTAMP': 'timestamp',
            'YEAR': 'year',
            'JSON': 'json'
        }
        
        # í¬ê¸° ì •ë³´ì™€ í•¨ê»˜ ì²˜ë¦¬
        for sql_key, dbml_value in type_mapping.items():
            if sql_type.startswith(sql_key):
                # í¬ê¸° ì •ë³´ë‚˜ enum ê°’ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
                size_part = sql_type[len(sql_key):].strip()
                if size_part:
                    return f"{dbml_value}{size_part}"
                else:
                    return dbml_value
        
        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬
        if sql_type.upper() == 'FOREIGN':
            # ì™¸ë˜í‚¤ ì»¬ëŸ¼ì€ ì¼ë°˜ì ìœ¼ë¡œ ì •ìˆ˜í˜•
            return 'int'
        
        # ë§¤í•‘ë˜ì§€ ì•Šì€ íƒ€ì…ì€ ì†Œë¬¸ìë¡œ ë³€í™˜
        return sql_type.lower()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    converter = DBMLConverter()
    
    # ìƒ˜í”Œ ë°ì´í„°
    sample_data = {
        'users': {
            'columns': [
                {
                    'name': 'id',
                    'type': 'BIGINT',
                    'size': '20',
                    'nullable': False,
                    'auto_increment': True,
                    'primary_key': True,
                    'unique': False,
                    'default': None
                },
                {
                    'name': 'username',
                    'type': 'VARCHAR',
                    'size': '50',
                    'nullable': False,
                    'auto_increment': False,
                    'primary_key': False,
                    'unique': False,
                    'default': None
                },
                {
                    'name': 'email',
                    'type': 'VARCHAR',
                    'size': '100',
                    'nullable': True,
                    'auto_increment': False,
                    'primary_key': False,
                    'unique': True,
                    'default': None
                }
            ],
            'constraints': [
                {
                    'type': 'primary_key',
                    'columns': ['id']
                },
                {
                    'type': 'unique',
                    'columns': ['email']
                }
            ]
        }
    }
    
    # DBML ë³€í™˜ í…ŒìŠ¤íŠ¸
    dbml_result = converter.convert_tables_to_dbml(sample_data, 'test_schema')
    print("DBML ë³€í™˜ ê²°ê³¼:")
    print(dbml_result)